---
title: 'Week 12 GLM Poisson and other GLMs: Sleuth Chapter 22 & Harrell on Regression
  Modeling Stratgies'
author: "Eugene D. Gallagher"
date: "11/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(car)
library(Sleuth3)
library(dplyr)     # data manipulation
library(ggformula) # graphics
library(rms)
library(Sleuth3)
```

***

# Homework 11 Solutions (5:30 PM - 6 PM)

## Basic 20.15 Spotted Owl Habitat

### Annie O'Connell

## Basic 21.22 Environmental Voting

### Eli Kurtz

## Supplemental 20.16 Bumpus Natural Selection

### Jessica Kittel

## Supplemental 21.20 Clever Hans Effect

### Yibiao Liang

## Master Problem 11: Analysis of Toxicology data with drc

### Rob DiGiavonni

***

# Chapter 22

## Case Studies

### Case Study 22.1 Age and Mating Scucess of Male Elephants---An Observational Study

![Sleuth3 Display 22.1](..\images\Display2201.jpg)
_Fit the Poisson Log-Linear Regression Model_

![Poisson Log-Linear Regression Model Sleuth3 p 677](..\images\Poissonmodel.jpg)

_Statistical Conclusion_

* The average number of successful matings increased with age, for male elephants bettween 25 and 50 years old

![Sleuth3 Display 22.2 2nd edition](..\images\Display2202_2nd.jpg)


![Sleuth3 Display 22.2 3rd edition](..\images\Display2202_3rd.jpg)
![Sleuth3 Display 22.2 Gallagher's Matlab program](..\images\Display2202_Matlab.jpg)
![Sleuth3 Display 22.2 OLS Regression with Gallagher's Matlab program](..\images\Display2202_OLS_Matlab.jpg)
![Sleuth3 Display 22.2 SPSS](..\images\Display2202_SPSS.jpg)
![Sleuth3 Display 22.2 Adam Loy's tidysleuth](..\images\display2202_tidy.jpeg)

* The data provided no evidence of a leveling off of mating with age (quadratic term 1-sided p value = 0.33)

* The estimated mean number of successful matings (in 8 years) for 27-year-old males was 1.31, and the mean increased by a factor of 2.00 for each 10 year increase in age up to about 50 years (95% confidence interval for the mulitplicative factor: 1.52 to 2.60)

_Scope of Inference_

* There may be bias due to measurement error in estimating the age of each elephant and lack of independence.


* Bias would also accrue if successful matings weren't successfully attributed.

* Attempting to apply to a larger population would requie careful attention to the method of sampling.

***

_Sleuth 3 Code for Case Study 20.1_

```{r Sleuth3 code1}
str(case2201)
attach(case2201)
```

_EXPLORATION AND MODEL BUILDING_ 

```{r Sleuth3 code2}
plot(Matings ~ Age,  log="y")
ageSquared  <- Age^2
myGlm1 <- glm(Matings ~ Age + ageSquared, family=poisson)
summary(myGlm1)  # No evidence of a need for ageSquared
```

_INFERENCE AND INTERPRETATION_

```{r Sleuth3 code3}
myGlm2  <- update(myGlm1, ~ . - ageSquared)
summary(myGlm2)
anova(myGlm2,myGlm1,test="Chisq") # May not be valid, many counts < 5
beta  <- myGlm2$coef
exp(beta[2])  #1.071107
exp(confint(myGlm2,2))  #1.042558 1.100360 
```

_Interpretation:_ Associated with each 1 year increase in age is a 7% increase in the mean number of matings (95% confidence interval 4% to 10% increase).

_GRAPHICAL DISPLAY FOR PRESENTATION_

```{r Sleuth3 code4}
plot(Matings ~ Age, ylab="Number of Successful Matings",
     xlab="Age of Male Elephant (Years)",
     main="Age and Number of Successful Matings for 41 African Elephants",
     pch=21, bg="green", cex=2, lwd=2)
dummyAge <- seq(min(Age),max(Age), length=50)
lp <- beta[1] + beta[2]*dummyAge
curve <- exp(lp)
lines(curve ~ dummyAge,lwd=2)  
detach(case2201)
```

_Adam Loy's tidysleuth code_

```{r case4201_tidy1}
options(digits = 4, show.signif.stars = FALSE)
```

_Plot the jittered data on a log scale_

```{r case4201_tidy2}
gf_jitter(log(Matings + 0.5) ~ Age, data = case2201, height = 0.25, width = 0.25, pch = 1) %>%
  gf_labs(x = "Age (years) -- Slightly Jittered", y = "Number of Matings (log scale)")
```

_Fit the Poisson glm, with quadratic terms._

```{r case4201_tidy3}
glm1 <- glm(Matings ~ Age + I(Age^2), data = case2201, family = poisson)
summary(glm1)
summary(fitted(glm1))
tidy(glm1)
```

_Eliminate the quadratic term_

```{r case4201_tidy4}
reduced <- update(glm1, . ~ . - I(Age^2))
summary(reduced)
```

_Calculate Wald confidence interval_

```{r case4201_tidy5}
beta1 <- coef(reduced)[2]
se <- sqrt(vcov(reduced)[2,2])
beta1 + c(-1, 1) * qnorm(.975) * se
exp(beta1 + c(-1, 1) * qnorm(.975) * se)
```

_Profile-likelihood confidence interval_

```{r case4201_tidy6}
confint(glm1)
```

_Compare the full and reduced models_

```{r case4201_tidy7}
anova(reduced, glm1, test = "Chisq")
```

![Gallagher's Matlab analysis of OLS, Poisson & Poisson quadratic](..\images\display2202_Matlab_OLS_quadratic.jpg)

***

### Case Study 22.2 Characteristics Associated with Salamander Habitat_--An Observational Study

* The Del Norte Salamander (_plethodon elongates_) is a small (5-7 cm) salamander found among rock rubble, rock outcrops, and moss-covered talus in a narrow range of norwest California. 

* To study the relationship to old-growth forest, researchers selected 47 sites from plausible salamander habitat in national forest and parkland. At each site, a 7 m x 7 m search area was examined for the number of salamanders. Display 22.3 shows the number of salamanders and characteristics of the forest cover.

![Sleuth2 Display 22.3](..\images\display2203_2nd.jpg)

* Statistical Conclusion

- After accounting for canopy cover, there is no evidence that the mean number os salamanders depends on forest age ( p = 0.78 from F = 0.53 with 6 and 35 df from a quasilikelihood fit to a log-linear model).

- Two distinct canopy cover conditions were evident: closed canopies with percentages > 70%  and open canopy with percentages < 70%. The salamanders followed different curved abundance patterns under the two conditions.

***

![Sleuth2 Display 22.4](..\images\display2204_2nd.jpg)
![Gallagher's Matlab model display](..\images\display2204_Matlab.jpg)

![Gallagher's Matlab Quasilikelihood model display](..\images\display2204_Matlab_Quasilikelihood.jpg)

***

![Sleuth2 Display 22.5](..\images\display2205_2nd.jpg)

***

Plot of Deviance residuals

![Sleuth3 Display 22.7](..\images\display2207_3rd.jpg)

***

_Sleuth 3 Code for Case Study 20.2_

_EXPLORATION AND MODEL BUILDING_

```{r Sleuth3cs2002_1, warning=FALSE}
attach(case2202)

logSalamanders <- log(Salamanders + .5)
logForestAge   <- log(ForestAge + .5)
myMatrix       <- cbind(PctCover,logForestAge,logSalamanders)

if (require(car)) { # Use car library
  scatterplotMatrix(myMatrix, diagonal="histogram", reg.line=FALSE, spread=FALSE)
}
```

_Fit the Poisson log-linear model_

```{r Sleuth3cs2002_2}
myGlm1  <- glm(Salamanders ~ PctCover + logForestAge + PctCover:logForestAge, 
               family=poisson)
summary(myGlm1)   # Backward elimination...
myGlm2 <- update(myGlm1, ~ . - PctCover:logForestAge)
summary(myGlm2)
myGlm3  <- update(myGlm2, ~ . - logForestAge)
summary(myGlm3)   # PctCover is the only explanatory variable remaining
```

_Plot the penultimate model_

```{r Sleuth3cs2002_3}
plot(Salamanders ~ PctCover)  # It appears that there are 2 distributions
# of Salamander counts; one for PctCover < 70 and one for PctCover > 70
```

_See if PctCover is associated Salamanders in each subset_

```{r Sleuth3cs2002_4}
myGlm4 <- glm(Salamanders ~ PctCover, family=poisson,subset=(PctCover > 70))
summary(myGlm4)           # No evidence of an effect for this subset
myGlm5 <- glm(Salamanders ~ PctCover, family=poisson,subset=(PctCover < 70))
summary(myGlm5)           # No evidence on this subset either
```

_INFERENCE  (2 means)_

```{r Sleuth3cs2002_5}
Group <- ifelse(PctCover > 70,"High","Low")
Group <- factor(Group, levels=c("Low","High") )  # Make "Low Cover" the ref group
myGlm6 <- glm(Salamanders ~ Group, family=poisson)
summary(myGlm6)
```

_GRAPHICAL DISPLAY FOR PRESENTATION_

```{r Sleuth3cs2002_6}
plot(Salamanders ~ PctCover, ylab="Number of Salamanders",
     xlab="Percentage of Canopy Covered",
     main="Number of Salamanders versus Percent Canopy Cover",
     pch=21,bg="green", cex=2, lwd=2)

beta <- myGlm6$coef
lines(c(0,55),exp(c(beta[1],beta[1])),lwd=2)
text(56,exp(beta[1]),paste("mean= ",round(exp(beta[1]),1)),adj=0)
lines(c(76,93),exp(c(beta[1]+beta[2],beta[1]+beta[2])),lwd=2)
text(56,exp(beta[1]+beta[2]),paste("mean=",round((beta[1]+beta[2]),1)),adj=-1)
detach(case2202)
```

_What a poor R graphic_ 

![Gallagher's Matlab Quasilikelihood model display](..\images\display2204_Matlab_Quasilikelihood.jpg)

***

_Adam Loy's (Carleton) tidySleuth case 22.2 code_

```{rRScs2202_tidy_1}
options(digits = 4, show.signif.stars = FALSE)
summary(case2202)
```

_## EXPLORATION AND MODEL BUILDING_

```{rRScs2202_tidy_2}
logSalamanders <- log(Salamanders + .5)
logForestAge   <- log(ForestAge + .5)
myMatrix       <- cbind(PctCover,logForestAge,logSalamanders)
if (require(car)) { # Use car library
  scatterplotMatrix(myMatrix, diagonal="histogram", reg.line=FALSE, spread=FALSE)
}
```

_Fit the Poisson glm__

```{rRScs2202_tidy_2}
myGlm1  <- glm(Salamanders ~ PctCover + logForestAge + PctCover:logForestAge, 
               family=poisson)
summary(myGlm1)   # Backward elimination...
myGlm2 <- update(myGlm1, ~ . - PctCover:logForestAge)
summary(myGlm2)
myGlm3  <- update(myGlm2, ~ . - logForestAge)
summary(myGlm3)   # PctCover is the only explanatory variable remaining
```

_Plot the data_

```{rRScs2202_tidy_2}
plot(Salamanders ~ PctCover)  # It appears that there are 2 distributions
```

Number of Salamander counts; one for PctCover < 70 and one for PctCover > 70

_See if PctCover is associated Salamanders in each subset_

```{rRScs2202_tidy_3}
myGlm4 <- glm(Salamanders ~ PctCover, family=poisson,subset=(PctCover > 70))
summary(myGlm4)           # No evidence of an effect for this subset
myGlm5 <- glm(Salamanders ~ PctCover, family=poisson,subset=(PctCover < 70))
summary(myGlm5)           # No evidence on this subset either
```

_INFERENCE  (2 means)_

```{rRScs2202_tidy_4}
Group <- ifelse(PctCover > 70,"High","Low")
Group <- factor(Group, levels=c("Low","High") )  # Make "Low Cover" the ref group
myGlm6 <- glm(Salamanders ~ Group, family=poisson)
summary(myGlm6)
```


```{rRScs2202_tidy_5}
# Using 70% as the dividing line
case2202$Closed <- ifelse(case2202$PctCover > 70,"closed", "open")

ssom <- glm(Salamanders ~ PctCover * ForestAge * Closed + I(PctCover^2) + I(ForestAge^2) + 
              I(PctCover^2):Closed + I(ForestAge^2):Closed, 
            data = case2202, family = poisson)
summary(ssom)

1 - pchisq(89.178, df = 35)

gf_point(residuals(ssom, type = "deviance") ~ fitted(ssom)) %>%
  gf_hline(yintercept = 0, color = "blue") %>%
  gf_hline(yintercept = 2, color = "gray60", linetype = 2)  %>%
  gf_hline(yintercept = -2, color = "gray60", linetype = 2) %>%
  gf_labs(x = "Fitted means", y = "Deviance residual")

# The full model via quasi-likelihood
ssom <- update(ssom, . ~ ., family = quasipoisson)

# The reduced (inferential) model
inferential_model <- glm(Salamanders ~ PctCover * Closed + I(PctCover^2) + 
                           I(PctCover^2):Closed, data = case2202, family = quasipoisson)

# drop-in-deviance F test
anova(inferential_model, ssom, test = "F")
```

_Plot the model_

```{rRScs2202_tidy_6}
aug <- augment(inferential_model)
gf_point(Salamanders ~ PctCover, data = aug) %>%
  gf_line(exp(.fitted) ~ PctCover, color = ~Closed) %>%
  gf_labs(x = "Percentage of Canopy Cover",
          y = "Salamander Count")

```

![tidySleuth Case Study 22.2 ](..\images\RScs2202_tidy.jpeg)

![RScs2202 Final Model from Matlab](..\images\RScs2202_FinalModel.jpg)
![Gallagher's Matlab Quasilikelihood model display](..\images\display2204_Matlab_Quasilikelihood.jpg)

***


## Melanie Jetter's Poisson Regression

![Jetter Poisson Regression EEOS611](..\images\Jetter_Poisson.jpg)
![Jetter Poisson Regression EEOS611](..\images\Jetter_Poisson_nb.jpg)

 ![Jetter Poisson Regression Model EEOS611](..\images\Jetter_Model.jpg)
 
***

## Another example of the need for negative binomial glms

 ![VerHoef Seals 2007](..\images\VerHoef.jpg)
 ![VerHoef Seals 2007](..\images\VerHoefFig2.jpg)
 
## Another Case Study Migrating Elk, a Poisson regression

![Robinson et al. (2013) AIC](..\images\RobinsonElk.jpg)


# Frank Harrell's Regression Modeling Strategies: Highlights

## Harrell's Modeling principles

### What can keep a sample of data from being appropriate for modeling: 

1. Most important predictor or response variables not collected

2. Subjects in the dataset are ill-defined or not representative of the population to which inferences are needed 

3. Data collection sites do not represent the population of sites

4. Key variables missing in large numbers of subjects

5. Data not missing at random

6. No operational definitions for key variables and/or measurement errors severe

7. No observer variability studies done

### What else can go wrong in modeling? 

1. The process generating the data is not stable.

2. The model is misspecified with regard to nonlinearities or interactions, or there are predictors missing.

3. The model is misspecified in terms of the transformation of the response variable or the model's distributional assumptions.

4. The model contains discontinuities (e.g., by categorizing continuous predictors or setting regression shapes with sudden changes) that can be gamed by users.

5. Correlations among subjects are not specified, or the correlation structure is misspecified, resulting in inefficient parameter estimates and overconfident inference.

6. The model is overfitted, resulting in predictions that are too extreme or positive associations that are false.

7. The user of the model relies on predictions obtained by extrapolating to combinations of predictor values well outside the range of the dataset used to develop the model.

8. Accurate and discriminating predictions can lead to behavior changes that make future predictions inaccurate.

### Comparing two models 

Level playing field (independent datasets, same number of candidate d.f., careful bootstrapping)

1.	Criteria

	a.	calibration

	b.	discrimination

	c.	face validity

	d.	measurement errors in required predictors

	e.	use of continuous predictors (which are usually better defined than categorical ones)

	f.	omission of â€œinsignicant"variables that nonetheless make sense as risk factors

	g.	simplicity (though this is less important with the availability of computers)

	h.	lack of fit for specific types of subjects

### Preferred Modeling Strategy in a Nutshell

1.	Decide how many d.f. can be spent

2.	Decide where to spend them

3.	Spend them

4.	Don't reconsider, especially if inference needed

Sample size requirements for binary logistic regression (Harrell 8-14)


# Harrell Example of Poisson Regressoin: Sicilian cardiovascular events after a smoking ban

```{r SicilyCVER_1}
# options (prType ='latex') # applies to printingmodelfits
getHdata (sicily ) #fetch dataset from hbiostat.org/data
d<-sicily
dd<-datadist (d); options (datadist = 'dd')
g <- function (x) exp(x) * 100000
off <-list ( stdpop = mean (d$ stdpop )) # offset for prediction (383464.4)
w <- geom_point (aes(x=time , y= rate ), data =d)
v <- geom_vline (aes( xintercept =37 , col=I('red')))
yl <- ylab ('Acute Coronary Cases Per 100,000')
f <- Glm(aces ~ offset(log(stdpop)) + rcs(time,6), data=d, family = poisson)
f$aic
```

# Plot the data

```{r SicilyCVER_2}
ggplot(Predict(f, fun=g, offset =off)) + w + v + yl
```

# Save knot locations

```{r SicilyCVER_3}
k <- attr (rcs(d$time, 6), 'parms')
k
kn <- k
```


# rcspline.eval is the rcs workhorse
```{r SicilyCVER_4}
h <-  function (x) cbind(rcspline.eval (x, kn),
                         sin=sin (2*pi*x/12), cos=cos (2*pi*x/12))
f <- Glm( aces ~ offset (log( stdpop )) + gTrans (time, h),
         data =d, family = poisson )
f$aic
```


```{r SicilyCVER_5}
ggplot (Predict(f, fun=g, offset =off)) + w + v + yl
```

# Next add more nodes near intervention to allow for sudden change

```{r SicilyCVER_6}
kn <- sort (c(k, c(36 , 37, 38)))
f <-Glm( aces ~ offset (log(stdpop)) + gTrans (time , h),
         data =d, family = poisson )
f$aic
```


```{r SicilyCVER_7}
ggplot(Predict (f, fun=g, offset =off)) + w + v + yl
```

# Now make the slow trend simpler (6 knots) and more finely control times at which predictions are requested, to handle discontinuity.

```{r SicilyCVER_8}
# Harrell uses greater than or equal 37, but I don't know how to code that
h <- function (x) cbind ( rcspline.eval (x, k),
                         sin=sin (2*pi*x/12) , cos=cos (2*pi*x/12),
                         jump =x > 36.999)
f <-  Glm( aces ~ offset (log( stdpop )) + gTrans (time, h),
         data =d, family = poisson)
f$aic

times <- sort (c(seq (0, 60, length =200), 36.998 , 37, 37.001 ))
```

# Final plot

```{r SicilyCVER_9}
ggplot(Predict(f, time =times ,fun=g, offset =off)) + w + v + yl
```


```{r SicilyCVER_10}
# Look at fit statistics, especially evidence for the jump
# summary(f)
# summary generates Latex code which is unreadable, i'll regenrate f with glm
f2 <-  glm( aces ~ offset (log( stdpop )) + gTrans (time, h),
           data =d, family = poisson)
# These two lines not in Harrell's code, but match his output.
summary(f2)
anova(f2,test="Chisq")

# Strong evidence for a jump effect
# gTrans(time, h)jump    -0.126814   0.031270   -4.055 5.00e-05 ***
exp(-0.126814) # 0.8808975
```

There was a decrease of 12% in cardiovascular events resulting from the cigarette ban with strong evidence for seasonality 

# Harrell's titanic analysis using binomial logistic regression and rcs

![Harrell's Titanic Analysis](..\images\Titanic.jpg)
